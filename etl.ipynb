{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4dc30eb-10b1-4ff1-8f8c-219c1838fdf5",
   "metadata": {},
   "source": [
    "# ETL Processes\n",
    "Use this notebook to develop the ETL process for each of your tables before completing the `etl.py` file to load the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ddc94a-11f0-44ea-b164-00c5a2f89eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import psycopg2\n",
    "import logging\n",
    "from datetime import datetime\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615c1ef4-80f3-41bd-bd30-be56907a201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(path:str)->list:\n",
    "    '''\n",
    "    Recursively scans a directory and returns absolute path of \n",
    "    json files\n",
    "    \n",
    "    Input(s)\n",
    "    path(str): path to directory which has to be scanned\n",
    "    Return\n",
    "    paths(list): list of paths to json data files\n",
    "    '''\n",
    "    paths = []\n",
    "    for roots,dirs,files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                paths.append(os.path.join(roots,file))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8962514-9186-47f5-9280-c9486ebadae2",
   "metadata": {},
   "source": [
    "# Process `song_data`\n",
    "In this first part, you'll perform ETL on the first dataset, `song_data`, to create the `songs` and `artists` dimensional tables.\n",
    "\n",
    "Let's perform ETL on a single song file and load a single record into each table to start.\n",
    "- Use the `get_files` function provided above to get a list of all song JSON files in `data/song_data`\n",
    "- Select the first song in this list\n",
    "- Read the song file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccff332-1648-498a-8b3e-774311aa88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_songs = \"./data/song_data\"\n",
    "paths_songs = get_paths(path_songs)\n",
    "def read_json(path):\n",
    "    with open(path,'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383e2d48-048d-42ac-8898-679658235a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SQL Connection and Database Creation Queries\n",
    "#### Create Database and Tables ####\n",
    "\n",
    "def create_conn(user_name,passwd,db_name='postgres'):\n",
    "    conn = psycopg2.connect(f\"dbname= {db_name} user={user_name} password={passwd}\")\n",
    "    conn.set_session(autocommit=True)\n",
    "    return conn\n",
    "\n",
    "def drop_if_db_exists(conn,db_name):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        logging.info(f\"Checking if {db_name} exists already\")\n",
    "        cur.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    except Exception as  e:\n",
    "        logging.error(f\"Could not drop database {db_name}, error {e}\")\n",
    "    cur.close()\n",
    "    \n",
    "    \n",
    "def createdb(conn,db_name):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        logging.info(f\"Creating database {db_name}\")\n",
    "        cur.execute(f\"CREATE DATABASE {db_name} WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not create database {db_name}, error {e}\")\n",
    "    cur.close\n",
    "\n",
    "def execute_query(conn,query):\n",
    "    logging.info(f\"Executing query {query}\")\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except:\n",
    "        logging.error(f\"Query: {query} failed\")\n",
    "        cur.rollback()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad30fe98-3ab2-47f4-ac88-08290e46a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Queries:- Song Data\n",
    "song_table_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS SONGS (\n",
    "song_id VARCHAR(100) PRIMARY KEY,\n",
    "title VARCHAR(100) NOT NULL,\n",
    "artist_id VARCHAR(100) NOT NUll,\n",
    "year INTEGER NOT NULL,\n",
    "duration FLOAT NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "artist_table_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS ARTISTS (\n",
    "artist_id VARCHAR(100) PRIMARY KEY,\n",
    "name VARCHAR(100) NOT NULL,\n",
    "location VARCHAR(100),\n",
    "latitude double precision,\n",
    "longitude double precision\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "song_table_insert = \"\"\"\n",
    "INSERT INTO songs (song_id,title,artist_id,year,duration) VALUES (%s,%s,%s,%s,%s)\n",
    "ON CONFLICT DO NOTHING;\n",
    "\"\"\"\n",
    "\n",
    "artist_table_insert = \"\"\"\n",
    "INSERT INTO artists (artist_id,name,location,latitude,longitude) VALUES (%s,%s,%s,%s,%s)\n",
    "ON CONFLICT DO NOTHING;\n",
    "\"\"\"\n",
    "\n",
    "def drop_table_query(tablename):\n",
    "    q = f'''\n",
    "    DROP TABLE IF EXISTS {tablename};\n",
    "    '''\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5292219b-d179-4c8e-b1e7-f60d6fe554ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song_files(path,conn):\n",
    "    curr = conn.cursor()\n",
    "    data = read_json(path)\n",
    "    #logging.info(\"Inserting data into Artist table\")\n",
    "    data_artist = [data.get('artist_id'),data.get('artist_name'),\n",
    "                                     data.get('artist_location'),\n",
    "                                     data.get('artist_latitude'),\n",
    "                                     data.get('artist_longitude')]\n",
    "    curr.execute(artist_table_insert,data_artist)\n",
    "    data_song = [data.get('song_id'),\n",
    "                                    data.get('title'),\n",
    "                                    data.get('artist_id'),\n",
    "                                    data.get('year'),\n",
    "                                    data.get('duration')]\n",
    "    curr.execute(song_table_insert,data_song)\n",
    "    curr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73df9df-c809-4a54-af5b-c96d38e76e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 11:16:32,516 - INFO - Checking if sparkify exists already\n",
      "2022-11-21 11:16:32,728 - INFO - Creating database sparkify\n"
     ]
    }
   ],
   "source": [
    "### Create Database ###\n",
    "conn = create_conn(user_name=\"postgres\",passwd=\"Gun125\")\n",
    "drop_if_db_exists(conn,'sparkify')\n",
    "createdb(conn,'sparkify')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abfb9ec-02e6-4c3e-86ff-a7d2901332c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 11:16:32,840 - INFO - Executing query \n",
      "CREATE TABLE IF NOT EXISTS SONGS (\n",
      "song_id VARCHAR(100) PRIMARY KEY,\n",
      "title VARCHAR(100) NOT NULL,\n",
      "artist_id VARCHAR(100) NOT NUll,\n",
      "year INTEGER NOT NULL,\n",
      "duration FLOAT NOT NULL\n",
      ");\n",
      "\n",
      "2022-11-21 11:16:32,845 - INFO - Executing query \n",
      "CREATE TABLE IF NOT EXISTS ARTISTS (\n",
      "artist_id VARCHAR(100) PRIMARY KEY,\n",
      "name VARCHAR(100) NOT NULL,\n",
      "location VARCHAR(100),\n",
      "latitude double precision,\n",
      "longitude double precision\n",
      ");\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create Songs and Artists Tables ###\n",
    "conn = create_conn(user_name=\"postgres\",passwd=\"Gun125\",db_name=\"sparkify\")\n",
    "execute_query(conn,song_table_create)\n",
    "execute_query(conn,artist_table_create)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45187a5c-b31e-4b7d-b6a2-cc13d60380b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert data into Songs and artists table ##\n",
    "conn = create_conn(user_name=\"postgres\",passwd=\"Gun125\",db_name=\"sparkify\")\n",
    "for path in paths_songs:\n",
    "    process_song_files(path,conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69fc833-2d66-431d-a657-c2f19d073951",
   "metadata": {},
   "source": [
    "# Process `log_data`\n",
    "In this part, you'll perform ETL on the second dataset, `log_data`, to create the `time` and `users` dimensional tables, as well as the `songplays` fact table.\n",
    "\n",
    "Let's perform ETL on a single log file and load a single record into each table.\n",
    "- Use the `get_paths` function provided above to get a list of all log JSON files in `data/log_data`\n",
    "- Select the first log file in this list\n",
    "- Read the log file and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d569231-46b8-486a-8529-1080d3f216b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SQL Queries log-data ###\n",
    "songplay_table_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS songplays (\n",
    "songplay_id SERIAL PRIMARY KEY,\n",
    "start_time TIMESTAMP NOT NULL, \n",
    "user_id INTEGER NOT NULL, \n",
    "level VARCHAR(50), \n",
    "song_id VARCHAR(50), \n",
    "artist_id VARCHAR(50), \n",
    "session_id INTEGER, \n",
    "location VARCHAR(50), \n",
    "user_agent VARCHAR(150)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "user_table_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS USERS (\n",
    "user_id INTEGER PRIMARY KEY,\n",
    "first_name VARCHAR(100),\n",
    "last_name VARCHAR(100),\n",
    "gender VARCHAR(50),\n",
    "level VARCHAR(50)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "time_table_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS time (\n",
    "start_time TIMESTAMP PRIMARY KEY,\n",
    "hour INTEGER,\n",
    "day INTEGER,\n",
    "week INTEGER,\n",
    "month INTEGER,\n",
    "year INTEGER,\n",
    "weekday VARCHAR\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "songplay_table_insert = (\"\"\"\n",
    "INSERT INTO songplays (songplay_id,start_time,user_id,level,\n",
    "                      song_id,artist_id,session_id,location,user_agent)\n",
    "VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "ON CONFLICT(songplay_id) DO NOTHING;\n",
    "\"\"\")\n",
    "user_table_insert = \"\"\"\n",
    "INSERT INTO USERS (user_id,first_name,last_name,gender,level)\n",
    "VALUES (%s,%s,%s,%s,%s)\n",
    "ON CONFLICT DO NOTHING;\n",
    "\"\"\"\n",
    "time_table_insert = \"\"\"\n",
    "INSERT INTO TIME (start_time,hour,day,week,month,year,weekday)\n",
    "VALUES (%s,%s,%s,%s,%s,%s,%s)\n",
    "ON CONFLICT DO NOTHING;\n",
    "\"\"\"\n",
    "\n",
    "song_select = \"\"\"\n",
    "select songs.song_id, songs.artist_id from songs\n",
    "join artists on artists.artist_id = songs.artist_id\n",
    "where artists.name = %s and\n",
    "songs.title = %s and\n",
    "songs.duration = %s;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d31761-3916-48d3-93bc-e99dc5fcf222",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process Log data ###\n",
    "path_logs = \"./data/log_data\"\n",
    "paths_logs = get_paths(path_logs)\n",
    "log_data = []\n",
    "for path in paths_logs:\n",
    "    with open(path,'r') as f:\n",
    "        log_data.extend(json.loads(x) for x in f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc0d18f-98d0-4cd8-a782-41bba38e13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_whitespace(val):\n",
    "    if val=='':\n",
    "        val = 'Null'\n",
    "    return val\n",
    "def get_user_info(data):\n",
    "    info = (validate_whitespace(data.get('userId','Null')), \n",
    "            validate_whitespace(data.get('firstName','Null')), \n",
    "            validate_whitespace(data.get('lastName','Null')), \n",
    "            validate_whitespace(data.get('gender','Null')), \n",
    "            validate_whitespace(data.get('level','Null')))\n",
    "    return info\n",
    "\n",
    "def get_time_info(data):\n",
    "    weekday_dict = {'0':'Sunday',\n",
    "               '1': 'Monday',\n",
    "               '2': 'Tuesday',\n",
    "               '3':'Wednesday',\n",
    "               '4':'Thursday',\n",
    "               '5': 'Friday',\n",
    "               '6':'Saturday'}\n",
    "    ts = data.get('ts')\n",
    "    ts = ts/1000\n",
    "    ts = datetime.fromtimestamp(ts)\n",
    "    hour = int(ts.strftime(\"%H\"))\n",
    "    day = int(ts.strftime(\"%d\"))\n",
    "    week = int(ts.strftime(\"%V\"))\n",
    "    month = int(ts.strftime(\"%m\"))\n",
    "    year = int(ts.strftime(\"%Y\"))\n",
    "    weekday = weekday_dict[ts.strftime(\"%w\")]\n",
    "    time_stamp = ts.strftime(\"%X\")\n",
    "    start_time = f\"{year}-{month}-{day} {time_stamp} zulu\"\n",
    "    info = (start_time, \n",
    "            hour, \n",
    "            day, \n",
    "            week, \n",
    "            month, \n",
    "            year, \n",
    "            weekday)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af836a7b-eef6-4ae0-bbbd-77c8d6e11c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_log_data(conn,log_data):\n",
    "    curr = conn.cursor()\n",
    "    user_data = []\n",
    "    time_data = []\n",
    "    execute_query(conn,songplay_table_create)\n",
    "    execute_query(conn,user_table_create)\n",
    "    execute_query(conn,time_table_create)\n",
    "    for index,row in enumerate(log_data):\n",
    "        if row.get('page')=='NextSong':\n",
    "            info_user = get_user_info(row)\n",
    "            info_time = get_time_info(row)\n",
    "            user_data.append(info_user)\n",
    "            time_data.append(info_time)\n",
    "            name = row.get('artist')\n",
    "            title = row.get('song')\n",
    "            duration = row.get('length')\n",
    "            curr.execute(song_select,(name,title,duration))\n",
    "            result = curr.fetchone()\n",
    "            if result:\n",
    "                song_id,artist_id = result\n",
    "            else:\n",
    "                song_id,artist_id = None, None\n",
    "            vals = [index, info_time[0],info_user[0],\n",
    "                    info_user[-1],song_id,artist_id,row.get('sessionId'),\n",
    "                    row.get('location'),row.get('userAgent')]\n",
    "            curr.execute(songplay_table_insert,vals)\n",
    "            curr.execute(user_table_insert,get_user_info(row))\n",
    "            curr.execute(time_table_insert,get_time_info(row))\n",
    "    curr.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63e2d9c-4cd7-4858-815f-088dd2c3be69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 11:16:38,494 - INFO - Executing query \n",
      "CREATE TABLE IF NOT EXISTS songplays (\n",
      "songplay_id SERIAL PRIMARY KEY,\n",
      "start_time TIMESTAMP NOT NULL, \n",
      "user_id INTEGER NOT NULL, \n",
      "level VARCHAR(50), \n",
      "song_id VARCHAR(50), \n",
      "artist_id VARCHAR(50), \n",
      "session_id INTEGER, \n",
      "location VARCHAR(50), \n",
      "user_agent VARCHAR(150)\n",
      ");\n",
      "\n",
      "2022-11-21 11:16:38,501 - INFO - Executing query \n",
      "CREATE TABLE IF NOT EXISTS USERS (\n",
      "user_id INTEGER PRIMARY KEY,\n",
      "first_name VARCHAR(100),\n",
      "last_name VARCHAR(100),\n",
      "gender VARCHAR(50),\n",
      "level VARCHAR(50)\n",
      ");\n",
      "\n",
      "2022-11-21 11:16:38,504 - INFO - Executing query \n",
      "CREATE TABLE IF NOT EXISTS time (\n",
      "start_time TIMESTAMP PRIMARY KEY,\n",
      "hour INTEGER,\n",
      "day INTEGER,\n",
      "week INTEGER,\n",
      "month INTEGER,\n",
      "year INTEGER,\n",
      "weekday VARCHAR\n",
      ");\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn =  create_conn(user_name=\"postgres\",passwd=\"Gun125\",db_name=\"sparkify\")\n",
    "process_log_data(conn,log_data)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ded2c-7d96-4abd-91d1-5f9bf2d6cc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ddf400-e560-423a-a654-03993c868b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
